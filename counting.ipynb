{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): MaskedConv2dStaticSamePadding(\n",
       "    3, 24, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "  )\n",
       "  (_bn0): BatchNorm(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        24, 24, kernel_size=(3, 3), stride=[1, 1], groups=24, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        24, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        4, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        24, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3), stride=[1, 1], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        96, 3, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        3, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (pooling): AvgPool2d(kernel_size=3, stride=(2, 2), padding=1)\n",
       "      (_bn1): BatchNorm(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        144, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        4, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        240, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        8, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (pooling): AvgPool2d(kernel_size=3, stride=(2, 2), padding=1)\n",
       "      (_bn1): BatchNorm(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        240, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        8, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        240, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        336, 336, kernel_size=(3, 3), stride=(1, 1), groups=336, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        336, 11, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        11, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        336, 336, kernel_size=(2, 2), stride=[1, 1], groups=336, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        336, 11, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        11, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        336, 72, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        72, 432, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        432, 432, kernel_size=(2, 2), stride=(1, 1), groups=432, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        432, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        14, 432, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        432, 72, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        72, 432, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        432, 432, kernel_size=(3, 3), stride=[2, 2], groups=432, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (pooling): AvgPool2d(kernel_size=3, stride=(2, 2), padding=1)\n",
       "      (_bn1): BatchNorm(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        432, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        14, 432, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        432, 88, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        528, 528, kernel_size=(3, 3), stride=(1, 1), groups=528, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        528, 17, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        17, 528, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        528, 528, kernel_size=(3, 3), stride=(1, 1), groups=528, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        528, 17, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        17, 528, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        528, 528, kernel_size=(2, 2), stride=[1, 1], groups=528, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        528, 17, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        17, 528, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        528, 104, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): MaskedConv2dStaticSamePadding(\n",
       "    104, 150, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_bn1): BatchNorm(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (_fc): MaskedLinear(in_features=150, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torchvision.models as models\n",
    "\n",
    "from data_utils import *\n",
    "from train_tools import *\n",
    "from models import *\n",
    "from counting import *\n",
    "from pthflops import count_ops\n",
    "\n",
    "opt = ConfLoader('./Config/main.json').opt\n",
    "\n",
    "dataloaders, dataset_sizes = cifar_100_setter(batch_size=opt.data.batch_size, \n",
    "                                              valid_size=opt.data.valid_size,\n",
    "                                              root=opt.data.root,\n",
    "                                              fixed_valid=opt.data.fixed_valid,\n",
    "                                              autoaugment=opt.data.autoaugment,\n",
    "                                              aug_policy=opt.data.aug_policy)\n",
    "\n",
    "avail_resource = 2.0\n",
    "resolution_coefficient = 1.4\n",
    "resolution_coefficient = round(math.pow(resolution_coefficient, avail_resource), 2)\n",
    "\n",
    "blocks_args1 = [\n",
    "    'r1_k3_s1_e1_i24_o16_se0.20', \n",
    "    'r1_k3_s1_e6_i16_o24_se0.20', \n",
    "    'r2_k3_s2_e6_i24_o40_se0.20',  \n",
    "    'r1_k3_s1_e6_i40_o56_se0.20',  \n",
    "    'r2_k3_s1_e6_i56_o72_se0.20',  \n",
    "    'r2_k3_s2_e6_i72_o88_se0.20',  \n",
    "    'r1_k3_s1_e6_i88_o104_se0.20'\n",
    "]\n",
    "\n",
    "blocks_args1, global_params1 = efficientnet(blocks_args=blocks_args1,\n",
    "                                           resolution_coefficient=resolution_coefficient,\n",
    "                                           width_coefficient=0.9, \n",
    "                                           depth_coefficient=1, \n",
    "                                           image_size=opt.model.param.image_size, \n",
    "                                           num_classes=opt.model.param.num_classes)\n",
    "\n",
    "model = EfficientNet(blocks_args1, \n",
    "                     global_params1)\n",
    "\n",
    "model.to(opt.trainhandler.device)\n",
    "\n",
    "blocks_args2 = [\n",
    "    'r1_k3_s1_e1_i24_o16_se0.20', \n",
    "    'r1_k3_s1_e6_i16_o24_se0.20', \n",
    "    'r2_k3_s2_e6_i24_o40_se0.20',  \n",
    "    'r2_k3_s2_e6_i40_o56_se0.20',  \n",
    "    'r2_k2_s1_e6_i56_o72_se0.20',  \n",
    "    'r3_k3_s2_e6_i72_o88_se0.20',  \n",
    "    'r1_k2_s1_e6_i88_o104_se0.20',\n",
    "]\n",
    "\n",
    "blocks_args2, global_params2 = efficientnet(blocks_args=blocks_args2,\n",
    "                                           resolution_coefficient=1,\n",
    "                                           width_coefficient=1, \n",
    "                                           depth_coefficient=1, \n",
    "                                           image_size=opt.model.param.image_size, \n",
    "                                           num_classes=opt.model.param.num_classes)\n",
    "\n",
    "model = EfficientNet(blocks_args2, \n",
    "                     global_params2)\n",
    "\n",
    "model.to(opt.trainhandler.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef _get_num_params(model):\\n    num = 0\\n    for params in model.parameters():\\n        num += params.view(-1).shape[0]\\n    return num\\n\\ndevice = torch.device(opt.trainhandler.device)\\n\\ninput_ex = torch.randn(4, 3, 32, 32).to(device)\\n# assume as if it were quantized to 16-bits without actually doing any quantization\\nflops = (count_ops(model, input_ex) / 4)\\nparams = _get_num_params(model)\\n\\nM = 1000000\\nprint(\"flops: {:.4f}M, params: {:.4f}M\".format(flops/M, params/M))\\n#print(\\'score: {:.4f} + {:.4f} = {:.4f}\\'.format(flops/(1170*M), params/(6.9*M), flops/(1170*M) + params/(6.9*M)))\\n#print(\\'score: {:.4f} + {:.4f} = {:.4f}\\'.format(flops/(10490*M), params/(36.5*M), flops/(10490*M) + params/(36.5*M)))\\nflops = 87.578 * M\\nprint(\\'score: {:.4f} + {:.4f} = {:.4f}\\'.format(flops/(10490*M), params/(36.5*M), flops/(10490*M) + params/(36.5*M)))\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def _get_num_params(model):\n",
    "    num = 0\n",
    "    for params in model.parameters():\n",
    "        num += params.view(-1).shape[0]\n",
    "    return num\n",
    "\n",
    "device = torch.device(opt.trainhandler.device)\n",
    "\n",
    "input_ex = torch.randn(4, 3, 32, 32).to(device)\n",
    "# assume as if it were quantized to 16-bits without actually doing any quantization\n",
    "flops = (count_ops(model, input_ex) / 4)\n",
    "params = _get_num_params(model)\n",
    "\n",
    "M = 1000000\n",
    "print(\"flops: {:.4f}M, params: {:.4f}M\".format(flops/M, params/M))\n",
    "#print('score: {:.4f} + {:.4f} = {:.4f}'.format(flops/(1170*M), params/(6.9*M), flops/(1170*M) + params/(6.9*M)))\n",
    "#print('score: {:.4f} + {:.4f} = {:.4f}'.format(flops/(10490*M), params/(36.5*M), flops/(10490*M) + params/(36.5*M)))\n",
    "flops = 87.578 * M\n",
    "print('score: {:.4f} + {:.4f} = {:.4f}'.format(flops/(10490*M), params/(36.5*M), flops/(10490*M) + params/(36.5*M)))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "op_name                     inp_size   kernel_size   in channels  out channels  params(MBytes)   mults(M)    adds(M)     MFLOPS\n",
      "==================================================\n",
      "_conv_stem                        63             3             3            24           0.001      0.369      0.332      0.700\n",
      "block_0                           31            -1            24            -1           0.002      0.335      0.292      0.627\n",
      "block_1                           31            -1            16            -1           0.011      2.584      2.295      4.879\n",
      "block_2                           31            -1            24            -1           0.024      2.754      2.487      5.241\n",
      "block_3                           15            -1            40            -1           0.051      2.594      2.454      5.049\n",
      "block_4                           15            -1            40            -1           0.055      2.810      2.643      5.453\n",
      "block_5                           15            -1            48            -1           0.081      4.150      3.948      8.098\n",
      "block_6                           15            -1            64            -1           0.124      6.226      6.002     12.228\n",
      "block_7                           15            -1            64            -1           0.137      3.809      3.640      7.449\n",
      "block_8                            7            -1            80            -1           0.194      2.078      2.017      4.095\n",
      "block_9                            7            -1            80            -1           0.209      2.266      2.193      4.459\n",
      "_conv_head                         7             1            96           136           0.026      0.330      0.320      0.650\n",
      "_avg_pooling                       7            -1           136             1           0.000      0.000      0.003      0.003\n",
      "_fc                                1            -1           136           100           0.027      0.007      0.007      0.014\n",
      "total                                                                                    0.942     30.312     28.633     58.945\n",
      "##################################################\n",
      "flops: 58.9451M, params: 0.9416M\n",
      "score: 0.0504 + 0.0341 = 0.0845\n",
      "##################################################\n",
      "flops: 58.9451M, params: 0.9416M\n",
      "score: 0.0056 + 0.0064 = 0.0121\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "from counting import *\n",
    "\n",
    "# add_bits_base=32, since 32 bit adds count 1 add.\n",
    "# mul_bits_base=32, since multiplications with 32 bit input count 1 multiplication.\n",
    "conv_stem = {'kernel': 3, 'stride': 2, 'out_channel': 24}\n",
    "last_ops = {'out_channel': 150, 'num_classes': 100}\n",
    "activation = 'swish'\n",
    "input_size = int(math.ceil(32 * resolution_coefficient))\n",
    "use_bias = False\n",
    "\n",
    "counter = MicroNetCounter(conv_stem, blocks_args1, global_params1, last_ops, activation, input_size, use_bias, add_bits_base=32, mul_bits_base=32)\n",
    "\n",
    "# Constants\n",
    "INPUT_BITS = 16\n",
    "ACCUMULATOR_BITS = 16\n",
    "PARAMETER_BITS = INPUT_BITS\n",
    "SUMMARIZE_BLOCKS = True\n",
    "SPARSITY = 0.0\n",
    "\n",
    "params, flops = counter.print_summary(SPARSITY, PARAMETER_BITS, ACCUMULATOR_BITS, INPUT_BITS, summarize_blocks=SUMMARIZE_BLOCKS)\n",
    "print('#'*50)\n",
    "print(\"flops: {:.4f}M, params: {:.4f}M\".format(flops, params))\n",
    "print('score: {:.4f} + {:.4f} = {:.4f}'.format(flops/(1170), params/(6.9*4), flops/(1170) + params/(6.9*4)))\n",
    "print('#'*50)\n",
    "print(\"flops: {:.4f}M, params: {:.4f}M\".format(flops, params))\n",
    "print('score: {:.4f} + {:.4f} = {:.4f}'.format(flops/(10490), params/(36.5*4), flops/(10490) + params/(36.5*4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "op_name                     inp_size   kernel_size   in channels  out channels  params(MBytes)   mults(M)    adds(M)     MFLOPS\n",
      "==================================================\n",
      "_conv_stem                        32             3             3            24           0.001      0.393      0.344      0.737\n",
      "block_0                           32            -1            24            -1           0.002      0.381      0.324      0.705\n",
      "block_1                           32            -1            16            -1           0.011      2.950      2.544      5.493\n",
      "block_2                           32            -1            24            -1           0.024      3.153      2.779      5.931\n",
      "block_3                           16            -1            40            -1           0.051      3.074      2.854      5.928\n",
      "block_4                           16            -1            40            -1           0.059      1.930      1.774      3.704\n",
      "block_5                            8            -1            56            -1           0.097      1.423      1.346      2.769\n",
      "block_6                            8            -1            56            -1           0.104      1.567      1.467      3.035\n",
      "block_7                            8            -1            72            -1           0.153      2.238      2.123      4.361\n",
      "block_8                            8            -1            72            -1           0.171      1.427      1.357      2.784\n",
      "block_9                            4            -1            88            -1           0.232      0.838      0.807      1.644\n",
      "block_10                           4            -1            88            -1           0.232      0.838      0.807      1.644\n",
      "block_11                           4            -1            88            -1           0.244      0.906      0.861      1.766\n",
      "_conv_head                         4             1           104           150           0.031      0.131      0.126      0.257\n",
      "_avg_pooling                       4            -1           150             1           0.000      0.000      0.001      0.001\n",
      "_fc                                1            -1           150           100           0.030      0.007      0.007      0.015\n",
      "total                                                                                    1.442     21.256     19.520     40.776\n",
      "##################################################\n",
      "flops: 40.7760M, params: 1.4419M\n",
      "score: 0.0349 + 0.0522 = 0.0871\n",
      "##################################################\n",
      "flops: 40.7760M, params: 1.4419M\n",
      "score: 0.0039 + 0.0099 = 0.0138\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "from counting import *\n",
    "\n",
    "# add_bits_base=32, since 32 bit adds count 1 add.\n",
    "# mul_bits_base=32, since multiplications with 32 bit input count 1 multiplication.\n",
    "conv_stem = {'kernel': 3, 'stride': 1, 'out_channel': 24}\n",
    "last_ops = {'out_channel': 150, 'num_classes': 100}\n",
    "activation = 'celu'\n",
    "input_size = 32\n",
    "use_bias = False\n",
    "\n",
    "counter = MicroNetCounter(conv_stem, blocks_args2, global_params2, last_ops, activation, input_size, use_bias, add_bits_base=32, mul_bits_base=32)\n",
    "\n",
    "# Constants\n",
    "INPUT_BITS = 16\n",
    "ACCUMULATOR_BITS = 16\n",
    "PARAMETER_BITS = INPUT_BITS\n",
    "SUMMARIZE_BLOCKS = True\n",
    "SPARSITY = 0.0\n",
    "\n",
    "params, flops = counter.print_summary(SPARSITY, PARAMETER_BITS, ACCUMULATOR_BITS, INPUT_BITS, summarize_blocks=SUMMARIZE_BLOCKS)\n",
    "print('#'*50)\n",
    "print(\"flops: {:.4f}M, params: {:.4f}M\".format(flops, params))\n",
    "print('score: {:.4f} + {:.4f} = {:.4f}'.format(flops/(1170), params/(6.9*4), flops/(1170) + params/(6.9*4)))\n",
    "print('#'*50)\n",
    "print(\"flops: {:.4f}M, params: {:.4f}M\".format(flops, params))\n",
    "print('score: {:.4f} + {:.4f} = {:.4f}'.format(flops/(10490), params/(36.5*4), flops/(10490) + params/(36.5*4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): MaskedConv2dStaticSamePadding(\n",
       "    3, 24, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "  )\n",
       "  (_bn0): BatchNorm(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        24, 24, kernel_size=(3, 3), stride=[1, 1], groups=24, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        24, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        4, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        24, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3), stride=[1, 1], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        96, 3, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        3, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (pooling): AvgPool2d(kernel_size=3, stride=(2, 2), padding=1)\n",
       "      (_bn1): BatchNorm(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        144, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        4, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        240, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        8, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (pooling): AvgPool2d(kernel_size=3, stride=(2, 2), padding=1)\n",
       "      (_bn1): BatchNorm(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        240, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        8, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        240, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        336, 336, kernel_size=(3, 3), stride=(1, 1), groups=336, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        336, 11, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        11, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        336, 336, kernel_size=(2, 2), stride=[1, 1], groups=336, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        336, 11, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        11, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        336, 72, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        72, 432, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        432, 432, kernel_size=(2, 2), stride=(1, 1), groups=432, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        432, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        14, 432, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        432, 72, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        72, 432, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        432, 432, kernel_size=(3, 3), stride=[2, 2], groups=432, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (pooling): AvgPool2d(kernel_size=3, stride=(2, 2), padding=1)\n",
       "      (_bn1): BatchNorm(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        432, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        14, 432, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        432, 88, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        528, 528, kernel_size=(3, 3), stride=(1, 1), groups=528, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        528, 17, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        17, 528, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        528, 528, kernel_size=(3, 3), stride=(1, 1), groups=528, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        528, 17, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        17, 528, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        528, 528, kernel_size=(2, 2), stride=[1, 1], groups=528, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        528, 17, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        17, 528, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        528, 104, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): MaskedConv2dStaticSamePadding(\n",
       "    104, 150, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_bn1): BatchNorm(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (_fc): MaskedLinear(in_features=150, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): MaskedConv2dStaticSamePadding(\n",
       "    3, 24, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "  )\n",
       "  (_bn0): BatchNorm(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (pooling): AvgPool2d(kernel_size=3, stride=(2, 2), padding=1)\n",
       "      (_bn1): BatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (pooling): AvgPool2d(kernel_size=3, stride=(2, 2), padding=1)\n",
       "      (_bn1): BatchNorm(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (pooling): AvgPool2d(kernel_size=3, stride=(2, 2), padding=1)\n",
       "      (_bn1): BatchNorm(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (pooling): AvgPool2d(kernel_size=3, stride=(2, 2), padding=1)\n",
       "      (_bn1): BatchNorm(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): MaskedConv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_conv): MaskedConv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): MaskedConv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): MaskedConv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): MaskedConv2dStaticSamePadding(\n",
       "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): MaskedConv2dStaticSamePadding(\n",
       "    320, 150, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_bn1): BatchNorm(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (_fc): MaskedLinear(in_features=150, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torchvision.models as models\n",
    "\n",
    "from data_utils import *\n",
    "from train_tools import *\n",
    "from models import *\n",
    "from counting import *\n",
    "from pthflops import count_ops\n",
    "\n",
    "opt = ConfLoader('./Config/main.json').opt\n",
    "\n",
    "dataloaders, dataset_sizes = cifar_100_setter(batch_size=opt.data.batch_size, \n",
    "                                              valid_size=opt.data.valid_size,\n",
    "                                              root=opt.data.root,\n",
    "                                              fixed_valid=opt.data.fixed_valid,\n",
    "                                              autoaugment=opt.data.autoaugment,\n",
    "                                              aug_policy=opt.data.aug_policy)\n",
    "\n",
    "blocks_args = [\n",
    "    'r1_k3_s1_e1_i32_o16_se0.25', \n",
    "    'r2_k3_s2_e6_i16_o24_se0.25', \n",
    "    'r2_k5_s2_e6_i24_o40_se0.25',  \n",
    "    'r3_k3_s2_e6_i40_o80_se0.25',  \n",
    "    'r3_k5_s1_e6_i80_o112_se0.25',  \n",
    "    'r4_k5_s2_e6_i112_o192_se0.25',  \n",
    "    'r1_k3_s1_e6_i192_o320_se0.25'\n",
    "]\n",
    "\n",
    "blocks_args, global_params = efficientnet(blocks_args=blocks_args,\n",
    "                                          resolution_coefficient=1,\n",
    "                                          width_coefficient=1, \n",
    "                                          depth_coefficient=1, \n",
    "                                          image_size=224, \n",
    "                                          num_classes=1000)\n",
    "\n",
    "model = EfficientNet(blocks_args, \n",
    "                     global_params)\n",
    "\n",
    "model.to(opt.trainhandler.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "op_name                     inp_size   kernel_size   in channels  out channels  params(MBytes)   mults(M)    adds(M)     MFLOPS\n",
      "==================================================\n",
      "_conv_stem                       224             3             3            32           0.002      6.021     11.239     17.261\n",
      "block_0                          112            -1            32            -1           0.003      5.821     10.839     16.659\n",
      "block_1                          112            -1            16            -1           0.012     17.010     31.010     48.020\n",
      "block_2                           56            -1            24            -1           0.021     14.452     27.548     42.000\n",
      "block_3                           56            -1            24            -1           0.030      9.992     18.855     28.848\n",
      "block_4                           28            -1            40            -1           0.062     10.540     20.514     31.054\n",
      "block_5                           28            -1            40            -1           0.073      6.236     12.000     18.236\n",
      "block_6                           14            -1            80            -1           0.204      8.289     16.295     24.584\n",
      "block_7                           14            -1            80            -1           0.204      8.289     16.295     24.584\n",
      "block_8                           14            -1            80            -1           0.250     10.547     20.717     31.264\n",
      "block_9                           14            -1           112            -1           0.414     16.879     33.361     50.240\n",
      "block_10                          14            -1           112            -1           0.414     16.879     33.361     50.240\n",
      "block_11                          14            -1           112            -1           0.522     11.232     22.132     33.364\n",
      "block_12                           7            -1           192            -1           1.171     11.798     23.424     35.222\n",
      "block_13                           7            -1           192            -1           1.171     11.798     23.424     35.222\n",
      "block_14                           7            -1           192            -1           1.171     11.798     23.424     35.222\n",
      "block_15                           7            -1           192            -1           1.429     14.959     29.689     44.649\n",
      "_conv_head                         7             1           320          1280           0.822     10.129     20.133     30.262\n",
      "_avg_pooling                       7            -1          1280             1           0.000      0.001      0.061      0.062\n",
      "_fc                                1            -1          1280          1000           2.562      0.640      1.280      1.920\n",
      "total                                                                                   10.535    203.312    395.601    598.913\n",
      "##################################################\n",
      "flops: 598.9129M, params: 10.5351M\n",
      "score: 0.5119 + 0.3817 = 0.8936\n",
      "##################################################\n",
      "flops: 598.9129M, params: 10.5351M\n",
      "score: 0.0571 + 0.0722 = 0.1293\n"
     ]
    }
   ],
   "source": [
    "from counting import *\n",
    "\n",
    "# add_bits_base=32, since 32 bit adds count 1 add.\n",
    "# mul_bits_base=32, since multiplications with 32 bit input count 1 multiplication.\n",
    "conv_stem = {'kernel': 3, 'stride': 2, 'out_channel': 32}\n",
    "last_ops = {'out_channel': 1280, 'num_classes': 1000}\n",
    "activation = 'swish'\n",
    "input_size = 224\n",
    "use_bias = True\n",
    "\n",
    "counter = MicroNetCounter(conv_stem, blocks_args, global_params, last_ops, activation, input_size, use_bias, add_bits_base=32, mul_bits_base=32)\n",
    "\n",
    "# Constants\n",
    "INPUT_BITS = 16\n",
    "ACCUMULATOR_BITS = 32\n",
    "PARAMETER_BITS = INPUT_BITS\n",
    "SUMMARIZE_BLOCKS = True\n",
    "SPARSITY = 0.0\n",
    "\n",
    "params, flops = counter.print_summary(SPARSITY, PARAMETER_BITS, ACCUMULATOR_BITS, INPUT_BITS, summarize_blocks=SUMMARIZE_BLOCKS)\n",
    "print('#'*50)\n",
    "print(\"flops: {:.4f}M, params: {:.4f}M\".format(flops, params))\n",
    "print('score: {:.4f} + {:.4f} = {:.4f}'.format(flops/(1170), params/(6.9*4), flops/(1170) + params/(6.9*4)))\n",
    "print('#'*50)\n",
    "print(\"flops: {:.4f}M, params: {:.4f}M\".format(flops, params))\n",
    "print('score: {:.4f} + {:.4f} = {:.4f}'.format(flops/(10490), params/(36.5*4), flops/(10490) + params/(36.5*4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv2D = collections.namedtuple(\n",
    "    'Conv2D', ['input_size', 'kernel_shape', 'strides', 'padding', 'use_bias',\n",
    "               'activation'])\n",
    "\n",
    "\"\"\"Operation definition for 2D depthwise convolution.\n",
    "Only difference compared to Conv2D is the kernel_shape[3] = 1.\n",
    "\"\"\"\n",
    "DepthWiseConv2D = collections.namedtuple(\n",
    "    'DepthWiseConv2D', ['input_size', 'kernel_shape', 'strides', 'padding',\n",
    "                        'use_bias', 'activation'])\n",
    "\n",
    "\"\"\"Operation definition for Global Average Pooling.\n",
    "Attributes:\n",
    "  input_size: int, Dimensions of the input image (square assumed).\n",
    "  n_channels: int, Number of output dimensions.\n",
    "\"\"\"\n",
    "GlobalAvg = collections.namedtuple('GlobalAvg', ['input_size', 'n_channels'])\n",
    "\n",
    "\"\"\"Operation definitions for elementwise multiplication and addition.\n",
    "Attributes:\n",
    "  input_size: int, Dimensions of the input image (square assumed).\n",
    "  n_channels: int, Number of output dimensions.\n",
    "\"\"\"\n",
    "Scale = collections.namedtuple('Scale', ['input_size', 'n_channels'])\n",
    "Add = collections.namedtuple('Add', ['input_size', 'n_channels'])\n",
    "\n",
    "\n",
    "\"\"\"Operation definitions for elementwise multiplication and addition.\n",
    "Attributes:\n",
    "  kernel_shape: list, of length 2. Shape of the weight matrix.\n",
    "  use_bias: bool, if true a bias term is added to the output.\n",
    "  activation: str, type of activation applied to the output.\n",
    "\"\"\"\n",
    "FullyConnected = collections.namedtuple(\n",
    "    'FullyConnected', ['kernel_shape', 'use_bias', 'activation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = [('_conv_stem', Conv2D(input_size=224, kernel_shape=[3, 3, 3, 32], strides=(2, 2), padding='same', use_bias=True, activation='swish')), ('block_0', [('_depthwise_conv', DepthWiseConv2D(input_size=112, kernel_shape=[3, 3, 32, 1], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_reduce_mean', GlobalAvg(input_size=112, n_channels=32)), ('_se_reduce', Conv2D(input_size=1, kernel_shape=[1, 1, 32, 8], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_expand', Conv2D(input_size=1, kernel_shape=[1, 1, 8, 32], strides=(1, 1), padding='same', use_bias=True, activation='sigmoid')), ('_se_scale', Scale(input_size=112, n_channels=32)), ('_project_conv', Conv2D(input_size=112, kernel_shape=[1, 1, 32, 16], strides=(1, 1), padding='same', use_bias=True, activation=None))]), ('block_1', [('_expand_conv', Conv2D(input_size=112, kernel_shape=[1, 1, 16, 96], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_depthwise_conv', DepthWiseConv2D(input_size=112, kernel_shape=[3, 3, 96, 1], strides=(2, 2), padding='same', use_bias=True, activation='swish')), ('_se_reduce_mean', GlobalAvg(input_size=56, n_channels=96)), ('_se_reduce', Conv2D(input_size=1, kernel_shape=[1, 1, 96, 4], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_expand', Conv2D(input_size=1, kernel_shape=[1, 1, 4, 96], strides=(1, 1), padding='same', use_bias=True, activation='sigmoid')), ('_se_scale', Scale(input_size=56, n_channels=96)), ('_project_conv', Conv2D(input_size=56, kernel_shape=[1, 1, 96, 24], strides=(1, 1), padding='same', use_bias=True, activation=None))]), ('block_2', [('_expand_conv', Conv2D(input_size=56, kernel_shape=[1, 1, 24, 144], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_depthwise_conv', DepthWiseConv2D(input_size=56, kernel_shape=[3, 3, 144, 1], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_reduce_mean', GlobalAvg(input_size=56, n_channels=144)), ('_se_reduce', Conv2D(input_size=1, kernel_shape=[1, 1, 144, 6], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_expand', Conv2D(input_size=1, kernel_shape=[1, 1, 6, 144], strides=(1, 1), padding='same', use_bias=True, activation='sigmoid')), ('_se_scale', Scale(input_size=56, n_channels=144)), ('_project_conv', Conv2D(input_size=56, kernel_shape=[1, 1, 144, 24], strides=(1, 1), padding='same', use_bias=True, activation=None)), ('_skip_add', Add(input_size=56, n_channels=144))]), ('block_3', [('_expand_conv', Conv2D(input_size=56, kernel_shape=[1, 1, 24, 144], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_depthwise_conv', DepthWiseConv2D(input_size=56, kernel_shape=[5, 5, 144, 1], strides=(2, 2), padding='same', use_bias=True, activation='swish')), ('_se_reduce_mean', GlobalAvg(input_size=28, n_channels=144)), ('_se_reduce', Conv2D(input_size=1, kernel_shape=[1, 1, 144, 6], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_expand', Conv2D(input_size=1, kernel_shape=[1, 1, 6, 144], strides=(1, 1), padding='same', use_bias=True, activation='sigmoid')), ('_se_scale', Scale(input_size=28, n_channels=144)), ('_project_conv', Conv2D(input_size=28, kernel_shape=[1, 1, 144, 40], strides=(1, 1), padding='same', use_bias=True, activation=None))]), ('block_4', [('_expand_conv', Conv2D(input_size=28, kernel_shape=[1, 1, 40, 240], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_depthwise_conv', DepthWiseConv2D(input_size=28, kernel_shape=[5, 5, 240, 1], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_reduce_mean', GlobalAvg(input_size=28, n_channels=240)), ('_se_reduce', Conv2D(input_size=1, kernel_shape=[1, 1, 240, 10], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_expand', Conv2D(input_size=1, kernel_shape=[1, 1, 10, 240], strides=(1, 1), padding='same', use_bias=True, activation='sigmoid')), ('_se_scale', Scale(input_size=28, n_channels=240)), ('_project_conv', Conv2D(input_size=28, kernel_shape=[1, 1, 240, 40], strides=(1, 1), padding='same', use_bias=True, activation=None)), ('_skip_add', Add(input_size=28, n_channels=240))]), ('block_5', [('_expand_conv', Conv2D(input_size=28, kernel_shape=[1, 1, 40, 240], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_depthwise_conv', DepthWiseConv2D(input_size=28, kernel_shape=[3, 3, 240, 1], strides=(2, 2), padding='same', use_bias=True, activation='swish')), ('_se_reduce_mean', GlobalAvg(input_size=14, n_channels=240)), ('_se_reduce', Conv2D(input_size=1, kernel_shape=[1, 1, 240, 10], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_expand', Conv2D(input_size=1, kernel_shape=[1, 1, 10, 240], strides=(1, 1), padding='same', use_bias=True, activation='sigmoid')), ('_se_scale', Scale(input_size=14, n_channels=240)), ('_project_conv', Conv2D(input_size=14, kernel_shape=[1, 1, 240, 80], strides=(1, 1), padding='same', use_bias=True, activation=None))]), ('block_6', [('_expand_conv', Conv2D(input_size=14, kernel_shape=[1, 1, 80, 480], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_depthwise_conv', DepthWiseConv2D(input_size=14, kernel_shape=[3, 3, 480, 1], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_reduce_mean', GlobalAvg(input_size=14, n_channels=480)), ('_se_reduce', Conv2D(input_size=1, kernel_shape=[1, 1, 480, 20], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_expand', Conv2D(input_size=1, kernel_shape=[1, 1, 20, 480], strides=(1, 1), padding='same', use_bias=True, activation='sigmoid')), ('_se_scale', Scale(input_size=14, n_channels=480)), ('_project_conv', Conv2D(input_size=14, kernel_shape=[1, 1, 480, 80], strides=(1, 1), padding='same', use_bias=True, activation=None)), ('_skip_add', Add(input_size=14, n_channels=480))]), ('block_7', [('_expand_conv', Conv2D(input_size=14, kernel_shape=[1, 1, 80, 480], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_depthwise_conv', DepthWiseConv2D(input_size=14, kernel_shape=[3, 3, 480, 1], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_reduce_mean', GlobalAvg(input_size=14, n_channels=480)), ('_se_reduce', Conv2D(input_size=1, kernel_shape=[1, 1, 480, 20], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_expand', Conv2D(input_size=1, kernel_shape=[1, 1, 20, 480], strides=(1, 1), padding='same', use_bias=True, activation='sigmoid')), ('_se_scale', Scale(input_size=14, n_channels=480)), ('_project_conv', Conv2D(input_size=14, kernel_shape=[1, 1, 480, 80], strides=(1, 1), padding='same', use_bias=True, activation=None)), ('_skip_add', Add(input_size=14, n_channels=480))]), ('block_8', [('_expand_conv', Conv2D(input_size=14, kernel_shape=[1, 1, 80, 480], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_depthwise_conv', DepthWiseConv2D(input_size=14, kernel_shape=[5, 5, 480, 1], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_reduce_mean', GlobalAvg(input_size=14, n_channels=480)), ('_se_reduce', Conv2D(input_size=1, kernel_shape=[1, 1, 480, 20], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_expand', Conv2D(input_size=1, kernel_shape=[1, 1, 20, 480], strides=(1, 1), padding='same', use_bias=True, activation='sigmoid')), ('_se_scale', Scale(input_size=14, n_channels=480)), ('_project_conv', Conv2D(input_size=14, kernel_shape=[1, 1, 480, 112], strides=(1, 1), padding='same', use_bias=True, activation=None))]), ('block_9', [('_expand_conv', Conv2D(input_size=14, kernel_shape=[1, 1, 112, 672], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_depthwise_conv', DepthWiseConv2D(input_size=14, kernel_shape=[5, 5, 672, 1], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_reduce_mean', GlobalAvg(input_size=14, n_channels=672)), ('_se_reduce', Conv2D(input_size=1, kernel_shape=[1, 1, 672, 28], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_expand', Conv2D(input_size=1, kernel_shape=[1, 1, 28, 672], strides=(1, 1), padding='same', use_bias=True, activation='sigmoid')), ('_se_scale', Scale(input_size=14, n_channels=672)), ('_project_conv', Conv2D(input_size=14, kernel_shape=[1, 1, 672, 112], strides=(1, 1), padding='same', use_bias=True, activation=None)), ('_skip_add', Add(input_size=14, n_channels=672))]), ('block_10', [('_expand_conv', Conv2D(input_size=14, kernel_shape=[1, 1, 112, 672], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_depthwise_conv', DepthWiseConv2D(input_size=14, kernel_shape=[5, 5, 672, 1], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_reduce_mean', GlobalAvg(input_size=14, n_channels=672)), ('_se_reduce', Conv2D(input_size=1, kernel_shape=[1, 1, 672, 28], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_expand', Conv2D(input_size=1, kernel_shape=[1, 1, 28, 672], strides=(1, 1), padding='same', use_bias=True, activation='sigmoid')), ('_se_scale', Scale(input_size=14, n_channels=672)), ('_project_conv', Conv2D(input_size=14, kernel_shape=[1, 1, 672, 112], strides=(1, 1), padding='same', use_bias=True, activation=None)), ('_skip_add', Add(input_size=14, n_channels=672))]), ('block_11', [('_expand_conv', Conv2D(input_size=14, kernel_shape=[1, 1, 112, 672], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_depthwise_conv', DepthWiseConv2D(input_size=14, kernel_shape=[5, 5, 672, 1], strides=(2, 2), padding='same', use_bias=True, activation='swish')), ('_se_reduce_mean', GlobalAvg(input_size=7, n_channels=672)), ('_se_reduce', Conv2D(input_size=1, kernel_shape=[1, 1, 672, 28], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_expand', Conv2D(input_size=1, kernel_shape=[1, 1, 28, 672], strides=(1, 1), padding='same', use_bias=True, activation='sigmoid')), ('_se_scale', Scale(input_size=7, n_channels=672)), ('_project_conv', Conv2D(input_size=7, kernel_shape=[1, 1, 672, 192], strides=(1, 1), padding='same', use_bias=True, activation=None))]), ('block_12', [('_expand_conv', Conv2D(input_size=7, kernel_shape=[1, 1, 192, 1152], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_depthwise_conv', DepthWiseConv2D(input_size=7, kernel_shape=[5, 5, 1152, 1], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_reduce_mean', GlobalAvg(input_size=7, n_channels=1152)), ('_se_reduce', Conv2D(input_size=1, kernel_shape=[1, 1, 1152, 48], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_expand', Conv2D(input_size=1, kernel_shape=[1, 1, 48, 1152], strides=(1, 1), padding='same', use_bias=True, activation='sigmoid')), ('_se_scale', Scale(input_size=7, n_channels=1152)), ('_project_conv', Conv2D(input_size=7, kernel_shape=[1, 1, 1152, 192], strides=(1, 1), padding='same', use_bias=True, activation=None)), ('_skip_add', Add(input_size=7, n_channels=1152))]), ('block_13', [('_expand_conv', Conv2D(input_size=7, kernel_shape=[1, 1, 192, 1152], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_depthwise_conv', DepthWiseConv2D(input_size=7, kernel_shape=[5, 5, 1152, 1], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_reduce_mean', GlobalAvg(input_size=7, n_channels=1152)), ('_se_reduce', Conv2D(input_size=1, kernel_shape=[1, 1, 1152, 48], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_expand', Conv2D(input_size=1, kernel_shape=[1, 1, 48, 1152], strides=(1, 1), padding='same', use_bias=True, activation='sigmoid')), ('_se_scale', Scale(input_size=7, n_channels=1152)), ('_project_conv', Conv2D(input_size=7, kernel_shape=[1, 1, 1152, 192], strides=(1, 1), padding='same', use_bias=True, activation=None)), ('_skip_add', Add(input_size=7, n_channels=1152))]), ('block_14', [('_expand_conv', Conv2D(input_size=7, kernel_shape=[1, 1, 192, 1152], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_depthwise_conv', DepthWiseConv2D(input_size=7, kernel_shape=[5, 5, 1152, 1], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_reduce_mean', GlobalAvg(input_size=7, n_channels=1152)), ('_se_reduce', Conv2D(input_size=1, kernel_shape=[1, 1, 1152, 48], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_expand', Conv2D(input_size=1, kernel_shape=[1, 1, 48, 1152], strides=(1, 1), padding='same', use_bias=True, activation='sigmoid')), ('_se_scale', Scale(input_size=7, n_channels=1152)), ('_project_conv', Conv2D(input_size=7, kernel_shape=[1, 1, 1152, 192], strides=(1, 1), padding='same', use_bias=True, activation=None)), ('_skip_add', Add(input_size=7, n_channels=1152))]), ('block_15', [('_expand_conv', Conv2D(input_size=7, kernel_shape=[1, 1, 192, 1152], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_depthwise_conv', DepthWiseConv2D(input_size=7, kernel_shape=[3, 3, 1152, 1], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_reduce_mean', GlobalAvg(input_size=7, n_channels=1152)), ('_se_reduce', Conv2D(input_size=1, kernel_shape=[1, 1, 1152, 48], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_expand', Conv2D(input_size=1, kernel_shape=[1, 1, 48, 1152], strides=(1, 1), padding='same', use_bias=True, activation='sigmoid')), ('_se_scale', Scale(input_size=7, n_channels=1152)), ('_project_conv', Conv2D(input_size=7, kernel_shape=[1, 1, 1152, 320], strides=(1, 1), padding='same', use_bias=True, activation=None))]), ('_conv_head', Conv2D(input_size=7, kernel_shape=[1, 1, 320, 1280], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_avg_pooling', GlobalAvg(input_size=7, n_channels=1280)), ('_fc', FullyConnected(kernel_shape=[1280, 1000], use_bias=True, activation=None))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mine = [('_conv_stem', Conv2D(input_size=224, kernel_shape=[3, 3, 3, 32], strides=(2, 2), padding='same', use_bias=True, activation='swish')), ('block_0', [('_depthwise_conv', DepthWiseConv2D(input_size=112, kernel_shape=[3, 3, 32, 1], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_reduce_mean', GlobalAvg(input_size=112, n_channels=32)), ('_se_reduce', Conv2D(input_size=1, kernel_shape=[1, 1, 32, 8], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_expand', Conv2D(input_size=1, kernel_shape=[1, 1, 8, 32], strides=(1, 1), padding='same', use_bias=True, activation='sigmoid')), ('_se_scale', Scale(input_size=112, n_channels=32)), ('_project_conv', Conv2D(input_size=112, kernel_shape=[1, 1, 32, 16], strides=(1, 1), padding='same', use_bias=True, activation=None))]), ('block_1', [('_expand_conv', Conv2D(input_size=112, kernel_shape=[1, 1, 16, 96], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_depthwise_conv', DepthWiseConv2D(input_size=112, kernel_shape=[3, 3, 96, 1], strides=(2, 2), padding='same', use_bias=True, activation='swish')), ('_se_reduce_mean', GlobalAvg(input_size=56, n_channels=96)), ('_se_reduce', Conv2D(input_size=1, kernel_shape=[1, 1, 96, 4], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_expand', Conv2D(input_size=1, kernel_shape=[1, 1, 4, 96], strides=(1, 1), padding='same', use_bias=True, activation='sigmoid')), ('_se_scale', Scale(input_size=56, n_channels=96)), ('_project_conv', Conv2D(input_size=56, kernel_shape=[1, 1, 96, 24], strides=(1, 1), padding='same', use_bias=True, activation=None))]), ('block_2', [('_expand_conv', Conv2D(input_size=56, kernel_shape=[1, 1, 24, 144], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_depthwise_conv', DepthWiseConv2D(input_size=56, kernel_shape=[3, 3, 144, 1], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_reduce_mean', GlobalAvg(input_size=56, n_channels=144)), ('_se_reduce', Conv2D(input_size=1, kernel_shape=[1, 1, 144, 6], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_expand', Conv2D(input_size=1, kernel_shape=[1, 1, 6, 144], strides=(1, 1), padding='same', use_bias=True, activation='sigmoid')), ('_se_scale', Scale(input_size=56, n_channels=144)), ('_project_conv', Conv2D(input_size=56, kernel_shape=[1, 1, 144, 24], strides=(1, 1), padding='same', use_bias=True, activation=None)), ('_skip_add', Add(input_size=56, n_channels=144))]), ('block_3', [('_expand_conv', Conv2D(input_size=56, kernel_shape=[1, 1, 24, 144], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_depthwise_conv', DepthWiseConv2D(input_size=56, kernel_shape=[5, 5, 144, 1], strides=(2, 2), padding='same', use_bias=True, activation='swish')), ('_se_reduce_mean', GlobalAvg(input_size=28, n_channels=144)), ('_se_reduce', Conv2D(input_size=1, kernel_shape=[1, 1, 144, 6], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_expand', Conv2D(input_size=1, kernel_shape=[1, 1, 6, 144], strides=(1, 1), padding='same', use_bias=True, activation='sigmoid')), ('_se_scale', Scale(input_size=28, n_channels=144)), ('_project_conv', Conv2D(input_size=28, kernel_shape=[1, 1, 144, 40], strides=(1, 1), padding='same', use_bias=True, activation=None))]), ('block_4', [('_expand_conv', Conv2D(input_size=28, kernel_shape=[1, 1, 40, 240], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_depthwise_conv', DepthWiseConv2D(input_size=28, kernel_shape=[5, 5, 240, 1], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_reduce_mean', GlobalAvg(input_size=28, n_channels=240)), ('_se_reduce', Conv2D(input_size=1, kernel_shape=[1, 1, 240, 10], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_expand', Conv2D(input_size=1, kernel_shape=[1, 1, 10, 240], strides=(1, 1), padding='same', use_bias=True, activation='sigmoid')), ('_se_scale', Scale(input_size=28, n_channels=240)), ('_project_conv', Conv2D(input_size=28, kernel_shape=[1, 1, 240, 40], strides=(1, 1), padding='same', use_bias=True, activation=None)), ('_skip_add', Add(input_size=28, n_channels=240))]), ('block_5', [('_expand_conv', Conv2D(input_size=28, kernel_shape=[1, 1, 40, 240], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_depthwise_conv', DepthWiseConv2D(input_size=28, kernel_shape=[3, 3, 240, 1], strides=(2, 2), padding='same', use_bias=True, activation='swish')), ('_se_reduce_mean', GlobalAvg(input_size=14, n_channels=240)), ('_se_reduce', Conv2D(input_size=1, kernel_shape=[1, 1, 240, 10], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_expand', Conv2D(input_size=1, kernel_shape=[1, 1, 10, 240], strides=(1, 1), padding='same', use_bias=True, activation='sigmoid')), ('_se_scale', Scale(input_size=14, n_channels=240)), ('_project_conv', Conv2D(input_size=14, kernel_shape=[1, 1, 240, 80], strides=(1, 1), padding='same', use_bias=True, activation=None))]), ('block_6', [('_expand_conv', Conv2D(input_size=14, kernel_shape=[1, 1, 80, 480], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_depthwise_conv', DepthWiseConv2D(input_size=14, kernel_shape=[3, 3, 480, 1], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_reduce_mean', GlobalAvg(input_size=14, n_channels=480)), ('_se_reduce', Conv2D(input_size=1, kernel_shape=[1, 1, 480, 20], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_expand', Conv2D(input_size=1, kernel_shape=[1, 1, 20, 480], strides=(1, 1), padding='same', use_bias=True, activation='sigmoid')), ('_se_scale', Scale(input_size=14, n_channels=480)), ('_project_conv', Conv2D(input_size=14, kernel_shape=[1, 1, 480, 80], strides=(1, 1), padding='same', use_bias=True, activation=None)), ('_skip_add', Add(input_size=14, n_channels=480))]), ('block_7', [('_expand_conv', Conv2D(input_size=14, kernel_shape=[1, 1, 80, 480], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_depthwise_conv', DepthWiseConv2D(input_size=14, kernel_shape=[3, 3, 480, 1], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_reduce_mean', GlobalAvg(input_size=14, n_channels=480)), ('_se_reduce', Conv2D(input_size=1, kernel_shape=[1, 1, 480, 20], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_expand', Conv2D(input_size=1, kernel_shape=[1, 1, 20, 480], strides=(1, 1), padding='same', use_bias=True, activation='sigmoid')), ('_se_scale', Scale(input_size=14, n_channels=480)), ('_project_conv', Conv2D(input_size=14, kernel_shape=[1, 1, 480, 80], strides=(1, 1), padding='same', use_bias=True, activation=None)), ('_skip_add', Add(input_size=14, n_channels=480))]), ('block_8', [('_expand_conv', Conv2D(input_size=14, kernel_shape=[1, 1, 80, 480], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_depthwise_conv', DepthWiseConv2D(input_size=14, kernel_shape=[5, 5, 480, 1], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_reduce_mean', GlobalAvg(input_size=14, n_channels=480)), ('_se_reduce', Conv2D(input_size=1, kernel_shape=[1, 1, 480, 20], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_expand', Conv2D(input_size=1, kernel_shape=[1, 1, 20, 480], strides=(1, 1), padding='same', use_bias=True, activation='sigmoid')), ('_se_scale', Scale(input_size=14, n_channels=480)), ('_project_conv', Conv2D(input_size=14, kernel_shape=[1, 1, 480, 112], strides=(1, 1), padding='same', use_bias=True, activation=None))]), ('block_9', [('_expand_conv', Conv2D(input_size=14, kernel_shape=[1, 1, 112, 672], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_depthwise_conv', DepthWiseConv2D(input_size=14, kernel_shape=[5, 5, 672, 1], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_reduce_mean', GlobalAvg(input_size=14, n_channels=672)), ('_se_reduce', Conv2D(input_size=1, kernel_shape=[1, 1, 672, 28], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_expand', Conv2D(input_size=1, kernel_shape=[1, 1, 28, 672], strides=(1, 1), padding='same', use_bias=True, activation='sigmoid')), ('_se_scale', Scale(input_size=14, n_channels=672)), ('_project_conv', Conv2D(input_size=14, kernel_shape=[1, 1, 672, 112], strides=(1, 1), padding='same', use_bias=True, activation=None)), ('_skip_add', Add(input_size=14, n_channels=672))]), ('block_10', [('_expand_conv', Conv2D(input_size=14, kernel_shape=[1, 1, 112, 672], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_depthwise_conv', DepthWiseConv2D(input_size=14, kernel_shape=[5, 5, 672, 1], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_reduce_mean', GlobalAvg(input_size=14, n_channels=672)), ('_se_reduce', Conv2D(input_size=1, kernel_shape=[1, 1, 672, 28], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_expand', Conv2D(input_size=1, kernel_shape=[1, 1, 28, 672], strides=(1, 1), padding='same', use_bias=True, activation='sigmoid')), ('_se_scale', Scale(input_size=14, n_channels=672)), ('_project_conv', Conv2D(input_size=14, kernel_shape=[1, 1, 672, 112], strides=(1, 1), padding='same', use_bias=True, activation=None)), ('_skip_add', Add(input_size=14, n_channels=672))]), ('block_11', [('_expand_conv', Conv2D(input_size=14, kernel_shape=[1, 1, 112, 672], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_depthwise_conv', DepthWiseConv2D(input_size=14, kernel_shape=[5, 5, 672, 1], strides=(2, 2), padding='same', use_bias=True, activation='swish')), ('_se_reduce_mean', GlobalAvg(input_size=7, n_channels=672)), ('_se_reduce', Conv2D(input_size=1, kernel_shape=[1, 1, 672, 28], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_expand', Conv2D(input_size=1, kernel_shape=[1, 1, 28, 672], strides=(1, 1), padding='same', use_bias=True, activation='sigmoid')), ('_se_scale', Scale(input_size=7, n_channels=672)), ('_project_conv', Conv2D(input_size=7, kernel_shape=[1, 1, 672, 192], strides=(1, 1), padding='same', use_bias=True, activation=None))]), ('block_12', [('_expand_conv', Conv2D(input_size=7, kernel_shape=[1, 1, 192, 1152], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_depthwise_conv', DepthWiseConv2D(input_size=7, kernel_shape=[5, 5, 1152, 1], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_reduce_mean', GlobalAvg(input_size=7, n_channels=1152)), ('_se_reduce', Conv2D(input_size=1, kernel_shape=[1, 1, 1152, 48], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_expand', Conv2D(input_size=1, kernel_shape=[1, 1, 48, 1152], strides=(1, 1), padding='same', use_bias=True, activation='sigmoid')), ('_se_scale', Scale(input_size=7, n_channels=1152)), ('_project_conv', Conv2D(input_size=7, kernel_shape=[1, 1, 1152, 192], strides=(1, 1), padding='same', use_bias=True, activation=None)), ('_skip_add', Add(input_size=7, n_channels=1152))]), ('block_13', [('_expand_conv', Conv2D(input_size=7, kernel_shape=[1, 1, 192, 1152], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_depthwise_conv', DepthWiseConv2D(input_size=7, kernel_shape=[5, 5, 1152, 1], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_reduce_mean', GlobalAvg(input_size=7, n_channels=1152)), ('_se_reduce', Conv2D(input_size=1, kernel_shape=[1, 1, 1152, 48], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_expand', Conv2D(input_size=1, kernel_shape=[1, 1, 48, 1152], strides=(1, 1), padding='same', use_bias=True, activation='sigmoid')), ('_se_scale', Scale(input_size=7, n_channels=1152)), ('_project_conv', Conv2D(input_size=7, kernel_shape=[1, 1, 1152, 192], strides=(1, 1), padding='same', use_bias=True, activation=None)), ('_skip_add', Add(input_size=7, n_channels=1152))]), ('block_14', [('_expand_conv', Conv2D(input_size=7, kernel_shape=[1, 1, 192, 1152], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_depthwise_conv', DepthWiseConv2D(input_size=7, kernel_shape=[5, 5, 1152, 1], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_reduce_mean', GlobalAvg(input_size=7, n_channels=1152)), ('_se_reduce', Conv2D(input_size=1, kernel_shape=[1, 1, 1152, 48], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_expand', Conv2D(input_size=1, kernel_shape=[1, 1, 48, 1152], strides=(1, 1), padding='same', use_bias=True, activation='sigmoid')), ('_se_scale', Scale(input_size=7, n_channels=1152)), ('_project_conv', Conv2D(input_size=7, kernel_shape=[1, 1, 1152, 192], strides=(1, 1), padding='same', use_bias=True, activation=None)), ('_skip_add', Add(input_size=7, n_channels=1152))]), ('block_15', [('_expand_conv', Conv2D(input_size=7, kernel_shape=[1, 1, 192, 1152], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_depthwise_conv', DepthWiseConv2D(input_size=7, kernel_shape=[3, 3, 1152, 1], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_reduce_mean', GlobalAvg(input_size=7, n_channels=1152)), ('_se_reduce', Conv2D(input_size=1, kernel_shape=[1, 1, 1152, 48], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_se_expand', Conv2D(input_size=1, kernel_shape=[1, 1, 48, 1152], strides=(1, 1), padding='same', use_bias=True, activation='sigmoid')), ('_se_scale', Scale(input_size=7, n_channels=1152)), ('_project_conv', Conv2D(input_size=7, kernel_shape=[1, 1, 1152, 320], strides=(1, 1), padding='same', use_bias=True, activation=None))]), ('_conv_head', Conv2D(input_size=7, kernel_shape=[1, 1, 320, 1280], strides=(1, 1), padding='same', use_bias=True, activation='swish')), ('_avg_pooling', GlobalAvg(input_size=7, n_channels=1280)), ('_fc', FullyConnected(kernel_shape=[1280, 1000], use_bias=True, activation=None))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold == mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for t, m in zip(threshold, mine):\n",
    "    if t != m:\n",
    "        print(i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
